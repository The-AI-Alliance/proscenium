{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01POz8PiyB5a"
   },
   "source": [
    "# Literature\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. Downloading two books from Project Gutenberg\n",
    "2. Chunking them\n",
    "3. Storing in a vector database\n",
    "4. Usint the query to find a similar chunk in the vector database to form the context for an LLM call (Retrieval Augmented Generation, aka \"RAG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1FxfLnYmRY7"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/The-AI-Alliance/proscenium.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggeRbYZ9mSsa"
   },
   "outputs": [],
   "source": [
    "%cd proscenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_UwY3bfmSqE"
   },
   "outputs": [],
   "source": [
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhoa_GJWmSnd"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    api_key = userdata.get('TOGETHER_API_KEY')\n",
    "    os.environ['TOGETHER_API_KEY'] = api_key\n",
    "    print(\"Pulled secrets from colab userdata\")\n",
    "except ImportError:\n",
    "    print(\"Not in colab.  Relying on environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_iC1uYgmSk2"
   },
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from rich.panel import Panel\n",
    "from rich.prompt import Prompt\n",
    "\n",
    "import asyncio\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDt2b7FEmSiQ"
   },
   "outputs": [],
   "source": [
    "model_id = \"together:meta-llama/Llama-3-70b-chat-hf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQIG0H2Ip8x5"
   },
   "source": [
    "# Prepare Vector Database from Document Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmT-3-IvmSfY"
   },
   "outputs": [],
   "source": [
    "import demo.domains.literature as domain\n",
    "from proscenium.verbs.read import url_to_file\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "for book in domain.books:\n",
    "    print(\"Book:\", book.title)\n",
    "    asyncio.run(url_to_file(book.url, book.data_file))\n",
    "    print(\"Local copy to chunk:\", book.data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_OCVu_NmScy"
   },
   "outputs": [],
   "source": [
    "from proscenium.verbs.vector_database import embedding_function\n",
    "\n",
    "embedding_fn = embedding_function(domain.embedding_model_id)\n",
    "print(\"Embedding model\", domain.embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBbGDyi_mSaL"
   },
   "outputs": [],
   "source": [
    "from proscenium.verbs.vector_database import vector_db\n",
    "\n",
    "milvus_uri = \"file:/milvus.db\"\n",
    "\n",
    "vector_db_client = vector_db(milvus_uri, overwrite=True)\n",
    "print(\"Vector db at uri\", milvus_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDPrapyZmSXU"
   },
   "outputs": [],
   "source": [
    "from proscenium.scripts.chunk_space import build_vector_db\n",
    "\n",
    "collection_name = \"literature_chunks\"\n",
    "\n",
    "build_vector_db([book.data_file for book in domain.books], vector_db_client, embedding_fn, collection_name)\n",
    "\n",
    "# vector_db_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_RgYK_ZskDV"
   },
   "source": [
    "# Answer User Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxuBMD3rsjoy"
   },
   "outputs": [],
   "source": [
    "question = \"What did Hermes say to Prometheus about giving fire to humans?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DcRYOR2mSQz"
   },
   "outputs": [],
   "source": [
    "from proscenium.scripts.rag import answer_question\n",
    "\n",
    "answer = answer_question(\n",
    "    question, domain.model_id, vector_db_client, embedding_fn, collection_name, True\n",
    ")\n",
    "\n",
    "print(Panel(answer, title=\"Assistant\"))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
